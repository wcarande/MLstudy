{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Study Group\n",
    "\n",
    "## Model Validation\n",
    "\n",
    "<img src=\"xkcd_ML.png\" style=\"width: 250px;\">\n",
    "\n",
    "The following comes from the sklearn examples of how to perform cross-validation on a model.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/testing split\n",
    "sklearn has a built-in training/testing split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features, target shape: (150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "print('Features, target shape:', iris.data.shape, iris.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape (X, y): (90, 4) (90,)\n",
      "Testing shape (X, y): (60, 4) (60,)\n"
     ]
    }
   ],
   "source": [
    "# Split with 40% of data in testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "\n",
    "print('Training shape (X, y):', X_train.shape, y_train.shape)\n",
    "print('Testing shape (X, y):', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC score: 0.966666666667\n"
     ]
    }
   ],
   "source": [
    "# Train support vector classification\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "print('SVC score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "For the iris dataset, perform support vector classification. Score the results 5 times with different splits each time.  If the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, KFold is used. StratifiedKFold preserves the percentage of samples from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CV_model(X, y, cv, clf):\n",
    "    scores = cross_val_score(clf, X, y, cv=cv)\n",
    "    print('SVC cross-validation scores:', scores)\n",
    "    # 95% confidence interval, mean and 2 * standard deviation\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % \n",
    "          (scores.mean(), scores.std() * 2))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC cross-validation scores: [ 0.96666667  1.          0.96666667  0.96666667  1.        ]\n",
      "Accuracy: 0.98 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "X, y = iris.data, iris.target\n",
    "cv = 5    # Number of splits\n",
    "\n",
    "scores = CV_model(X, y, cv, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] [0]\n",
      "[0 2 3] [1]\n",
      "[0 1 3] [2]\n",
      "[0 1 2] [3]\n"
     ]
    }
   ],
   "source": [
    "# Leave one out\n",
    "loo = LeaveOneOut()\n",
    "X = [1, 2, 3, 4]\n",
    "\n",
    "for train, test in loo.split(X):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Search\n",
    "\n",
    "http://scikit-learn.org/stable/modules/grid_search.html\n",
    "\n",
    "### Exhaustive Grid Search\n",
    "Iterate through every possible combination of hyperparameters.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10, 100, 1000]}\n",
    "svr = svm.SVC()\n",
    "clf = GridSearchCV(svr, parameters)\n",
    "clf.fit(iris.data, iris.target)\n",
    "\n",
    "# Print the best parameters\n",
    "print(clf.cv_results_['params'][clf.best_index_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search\n",
    "\n",
    "Not all parameter values are used. A fixed number of parameter settings is sampled from the specified distributions.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=20, n_jobs=1,\n",
       "          param_distributions={'max_depth': [3, None], 'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x10b5a6128>, 'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x10b878828>, 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x10b8789b0>, 'bootstrap': [True, False], 'criterion': ['gini', 'entropy']},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get some data\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(2, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "random_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 6,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 9}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the best parameters\n",
    "random_search.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
